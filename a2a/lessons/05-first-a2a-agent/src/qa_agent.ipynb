{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "350c7056",
   "metadata": {},
   "source": [
    "# Lesson 05 ‚Äî Building Your First A2A Agent\n",
    "\n",
    "Build a standalone QA agent powered by **GitHub Phi-4** that answers questions about insurance policies.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Configure the OpenAI-compatible API for GitHub Models\n",
    "- Load domain knowledge and inject it into a system prompt\n",
    "- Build a `QAAgent` async class\n",
    "- Test the agent standalone before adding A2A protocol layers\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- GitHub account with a [Personal Access Token](https://github.com/settings/tokens) (no special scopes)\n",
    "- `GITHUB_TOKEN` environment variable set\n",
    "- Python 3.10+\n",
    "\n",
    "> **GitHub Models docs:** [docs.github.com/en/github-models](https://docs.github.com/en/github-models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4125e711",
   "metadata": {},
   "source": [
    "## Step 1 ‚Äî Install Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0db6e0b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T21:32:41.767155Z",
     "iopub.status.busy": "2026-02-27T21:32:41.767155Z",
     "iopub.status.idle": "2026-02-27T21:32:41.840935Z",
     "shell.execute_reply": "2026-02-27T21:32:41.840935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ Dependencies ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Dependencies ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# openai        ‚Üí OpenAI-compatible SDK (used to call GitHub Models / Phi-4)\n",
    "# python-dotenv ‚Üí Loads GITHUB_TOKEN from the .env file automatically\n",
    "#\n",
    "# If you have the venv active (a2a-examples kernel selected) these are already\n",
    "# installed. Run this cell anyway to ensure the kernel is up to date.\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "%pip install openai python-dotenv --quiet\n",
    "print(\"‚úÖ Dependencies ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da3ce57f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T21:32:41.842135Z",
     "iopub.status.busy": "2026-02-27T21:32:41.842135Z",
     "iopub.status.idle": "2026-02-27T21:32:41.851402Z",
     "shell.execute_reply": "2026-02-27T21:32:41.851402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded .env from: y:\\.sources\\localm-tuts\\a2a\\_examples\\.env\n",
      "‚úÖ GITHUB_TOKEN is set (github_p...)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "# ‚îÄ‚îÄ Load secrets from .env ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# find_dotenv() searches upward from this notebook's working directory.\n",
    "# It will find _examples/.env which contains GITHUB_TOKEN.\n",
    "#\n",
    "# To set up your .env:\n",
    "#   cp _examples/.env.example _examples/.env\n",
    "#   # then edit .env and add:  GITHUB_TOKEN=ghp_your_token_here\n",
    "#\n",
    "# Get a free GitHub PAT (no special scopes needed):\n",
    "#   https://github.com/settings/tokens\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "env_path = find_dotenv(raise_error_if_not_found=False)\n",
    "if env_path:\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"‚úÖ Loaded .env from: {env_path}\")\n",
    "else:\n",
    "    print(\"‚ö†  .env not found ‚Äî set GITHUB_TOKEN manually below if needed\")\n",
    "    # Uncomment and paste your token if .env is not available:\n",
    "    # os.environ[\"GITHUB_TOKEN\"] = \"ghp_your_token_here\"\n",
    "\n",
    "token = os.environ.get(\"GITHUB_TOKEN\", \"\")\n",
    "if token:\n",
    "    print(f\"‚úÖ GITHUB_TOKEN is set ({token[:8]}...)\")\n",
    "else:\n",
    "    print(\"‚ùå GITHUB_TOKEN is NOT set ‚Äî cells below will fail until you set it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1f8f13",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Configure the Model Client\n",
    "\n",
    "GitHub Models provides an **OpenAI-compatible API**. We use the standard `openai` package,\n",
    "pointed at `https://models.inference.ai.azure.com` instead of OpenAI's endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a50cc29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T21:32:41.853664Z",
     "iopub.status.busy": "2026-02-27T21:32:41.852664Z",
     "iopub.status.idle": "2026-02-27T21:32:42.672588Z",
     "shell.execute_reply": "2026-02-27T21:32:42.672588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Client configured ‚Äî base_url: https://models.inference.ai.azure.com\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# Load .env file if present (optional ‚Äî you can also export GITHUB_TOKEN directly)\n",
    "load_dotenv()\n",
    "\n",
    "# Verify token is set\n",
    "assert os.environ.get(\"GITHUB_TOKEN\"), \"Set GITHUB_TOKEN environment variable first!\"\n",
    "\n",
    "# Create the async OpenAI client pointing at GitHub Models\n",
    "client = AsyncOpenAI(\n",
    "    base_url=\"https://models.inference.ai.azure.com\",\n",
    "    api_key=os.environ[\"GITHUB_TOKEN\"],\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Client configured ‚Äî base_url: {client.base_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf470ceb",
   "metadata": {},
   "source": [
    "## Step 3 ‚Äî Quick Model Test\n",
    "\n",
    "Before building the agent, verify that the model connection works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8015197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T21:32:42.674613Z",
     "iopub.status.busy": "2026-02-27T21:32:42.674613Z",
     "iopub.status.idle": "2026-02-27T21:32:45.320158Z",
     "shell.execute_reply": "2026-02-27T21:32:45.319144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: phi4\n",
      "Answer: 2 + 2 equals 4.\n"
     ]
    }
   ],
   "source": [
    "response = await client.chat.completions.create(\n",
    "    model=\"Phi-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is 2 + 2?\"}],\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "print(f\"Model: {response.model}\")\n",
    "print(f\"Answer: {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6338f9f",
   "metadata": {},
   "source": [
    "## Step 4 ‚Äî Load Domain Knowledge\n",
    "\n",
    "The agent needs a knowledge base to answer domain-specific questions.\n",
    "We load an insurance policy document and inject it into the system prompt.\n",
    "\n",
    "This is **RAG-lite** ‚Äî simple and effective for bounded domains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d103ab51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T21:32:45.323159Z",
     "iopub.status.busy": "2026-02-27T21:32:45.322158Z",
     "iopub.status.idle": "2026-02-27T21:32:45.339306Z",
     "shell.execute_reply": "2026-02-27T21:32:45.338288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Loaded 1763 characters of domain knowledge\n",
      "üìù System prompt: 2024 characters\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a helpful insurance policy assistant.\n",
    "Use the following policy document to answer questions accurately.\n",
    "If the answer is not in the document, say so clearly.\n",
    "Always cite the relevant section when possible.\n",
    "\n",
    "--- POLICY DOCUMENT ---\n",
    "{policy_text}\n",
    "--- END DOCUMENT ---\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_knowledge(path: str) -> str:\n",
    "    \"\"\"Load a knowledge document from disk.\"\"\"\n",
    "    return Path(path).read_text(encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "# Load the insurance policy\n",
    "knowledge = load_knowledge(\"data/insurance_policy.txt\")\n",
    "system_prompt = SYSTEM_PROMPT.format(policy_text=knowledge)\n",
    "\n",
    "print(f\"üìÑ Loaded {len(knowledge)} characters of domain knowledge\")\n",
    "print(f\"üìù System prompt: {len(system_prompt)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be69ff92",
   "metadata": {},
   "source": [
    "## Step 5 ‚Äî Build the QAAgent Class\n",
    "\n",
    "The agent encapsulates:\n",
    "\n",
    "- Model client (AsyncOpenAI ‚Üí GitHub Phi-4)\n",
    "- Domain knowledge (loaded from file)\n",
    "- System prompt (template with injected knowledge)\n",
    "\n",
    "**Key design decisions:**\n",
    "| Decision | Choice | Rationale |\n",
    "|---|---|---|\n",
    "| Async interface | `async def query()` | A2A servers are async ‚Äî start async from day one |\n",
    "| Class pattern | `QAAgent` class | Clean separation for AgentExecutor wrapping (Lesson 6) |\n",
    "| Low temperature | `0.2` | Factual Q&A needs deterministic responses |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "373adef7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T21:32:45.342325Z",
     "iopub.status.busy": "2026-02-27T21:32:45.341301Z",
     "iopub.status.idle": "2026-02-27T21:32:45.347302Z",
     "shell.execute_reply": "2026-02-27T21:32:45.347302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ QAAgent class defined\n"
     ]
    }
   ],
   "source": [
    "class QAAgent:\n",
    "    \"\"\"Question-answering agent backed by GitHub Phi-4.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        knowledge_path: str,\n",
    "        model: str = \"Phi-4\",\n",
    "        temperature: float = 0.2,\n",
    "    ):\n",
    "        self.client = AsyncOpenAI(\n",
    "            base_url=\"https://models.inference.ai.azure.com\",\n",
    "            api_key=os.environ[\"GITHUB_TOKEN\"],\n",
    "        )\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.knowledge = load_knowledge(knowledge_path)\n",
    "        self.system_prompt = SYSTEM_PROMPT.format(\n",
    "            policy_text=self.knowledge\n",
    "        )\n",
    "\n",
    "    async def query(self, question: str) -> str:\n",
    "        \"\"\"Send a question to Phi-4 and return the answer.\"\"\"\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "            temperature=self.temperature,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "print(\"‚úÖ QAAgent class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c173e2",
   "metadata": {},
   "source": [
    "## Step 6 ‚Äî Test the Agent\n",
    "\n",
    "**Always test standalone before wrapping in A2A.** This verifies:\n",
    "\n",
    "- Model connectivity (GitHub Models endpoint)\n",
    "- Knowledge injection (system prompt)\n",
    "- Response quality (grounded, factual answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ee45cf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T21:32:45.349306Z",
     "iopub.status.busy": "2026-02-27T21:32:45.349306Z",
     "iopub.status.idle": "2026-02-27T21:32:45.667834Z",
     "shell.execute_reply": "2026-02-27T21:32:45.667834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent created with 1763 chars of knowledge\n"
     ]
    }
   ],
   "source": [
    "# Create the agent\n",
    "agent = QAAgent(\"data/insurance_policy.txt\")\n",
    "print(f\"‚úÖ Agent created with {len(agent.knowledge)} chars of knowledge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e5775b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T21:32:45.669838Z",
     "iopub.status.busy": "2026-02-27T21:32:45.669838Z",
     "iopub.status.idle": "2026-02-27T21:32:57.537108Z",
     "shell.execute_reply": "2026-02-27T21:32:57.537108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì What is the deductible for the Standard plan?\n",
      "\n",
      "üí¨ The deductible for the Standard plan under the ACME Insurance policy is as follows:\n",
      "\n",
      "- Standard Plan Deductible: $500 per incident\n",
      "- Emergency Room Deductible: $250 per visit\n",
      "- Prescription Drug Deductible: $100 per year\n",
      "\n",
      "These details are outlined in the \"DEDUCTIBLES\" section of the policy document.\n"
     ]
    }
   ],
   "source": [
    "# Test question 1: Specific fact\n",
    "answer = await agent.query(\"What is the deductible for the Standard plan?\")\n",
    "print(\"‚ùì What is the deductible for the Standard plan?\\n\")\n",
    "print(f\"üí¨ {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2f12c1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T21:32:57.539115Z",
     "iopub.status.busy": "2026-02-27T21:32:57.539115Z",
     "iopub.status.idle": "2026-02-27T21:33:12.465791Z",
     "shell.execute_reply": "2026-02-27T21:33:12.465791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Are cosmetic procedures covered?\n",
      "\n",
      "üí¨ Cosmetic procedures are not covered under the ACME Insurance Standard Policy, except when they are medically necessary. This is specified in the \"EXCLUSIONS\" section of the policy document. \n",
      "\n",
      "Relevant section: \n",
      "- \"Cosmetic procedures (unless medically necessary)\"\n"
     ]
    }
   ],
   "source": [
    "# Test question 2: Coverage question\n",
    "answer = await agent.query(\"Are cosmetic procedures covered?\")\n",
    "print(\"‚ùì Are cosmetic procedures covered?\\n\")\n",
    "print(f\"üí¨ {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a5a2cab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T21:33:12.467795Z",
     "iopub.status.busy": "2026-02-27T21:33:12.467795Z",
     "iopub.status.idle": "2026-02-27T21:33:25.119408Z",
     "shell.execute_reply": "2026-02-27T21:33:25.119408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì What is the capital of France?\n",
      "\n",
      "üí¨ I'm sorry, but the information about the capital of France is not included in the policy document provided. However, I can tell you that the capital of France is Paris. If you have any questions related to the ACME Insurance policy, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Test question 3: Out-of-scope question (should say \"not in document\")\n",
    "answer = await agent.query(\"What is the capital of France?\")\n",
    "print(\"‚ùì What is the capital of France?\\n\")\n",
    "print(f\"üí¨ {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7869c12",
   "metadata": {},
   "source": [
    "## Step 7 ‚Äî Experiment\n",
    "\n",
    "Try these variations:\n",
    "\n",
    "- Change the `temperature` (0.0 for max determinism, 0.8 for more creativity)\n",
    "- Ask follow-up questions about coverage limits, claims process, etc.\n",
    "- Ask questions not covered by the document ‚Äî the agent should say so clearly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbe6633a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T21:33:25.121414Z",
     "iopub.status.busy": "2026-02-27T21:33:25.121414Z",
     "iopub.status.idle": "2026-02-27T21:33:33.976623Z",
     "shell.execute_reply": "2026-02-27T21:33:33.976623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì How much is the monthly premium?\n",
      "\n",
      "üí¨ The monthly premium for the Standard Plan is $150. This information is found in the \"COVERAGE SUMMARY\" section of the policy document.\n"
     ]
    }
   ],
   "source": [
    "# Try your own question!\n",
    "your_question = \"How much is the monthly premium?\"\n",
    "\n",
    "answer = await agent.query(your_question)\n",
    "print(f\"‚ùì {your_question}\\n\")\n",
    "print(f\"üí¨ {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70181b55",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This QAAgent is the **foundation** for every A2A agent in this course.\n",
    "\n",
    "- **Lesson 6** ‚Üí Wrap this agent as an A2A server (AgentExecutor + Agent Card)\n",
    "- **Lesson 7** ‚Üí Build a client that discovers and calls the server\n",
    "\n",
    "The async class pattern ‚Äî `QAAgent` with `async def query()` ‚Äî is the core\n",
    "that Lesson 6 wraps with the A2A SDK's `AgentExecutor` interface.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "A2A Examples (Python 3.11)",
   "language": "python",
   "name": "a2a-examples"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
