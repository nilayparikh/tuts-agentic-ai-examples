{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cc8ce06",
   "metadata": {},
   "source": [
    "# Lesson 05 — Building Your First A2A Agent\n",
    "\n",
    "Build a standalone agent with **multiple skills** that handles Q&A, claims filing\n",
    "(multi-turn), and structured data output.\n",
    "Supports **GitHub Models** (free, cloud) and **AI Toolkit LocalFoundry** (local,\n",
    "no token required).\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Select a model provider (GitHub Models or LocalFoundry)\n",
    "- Configure an OpenAI-compatible API client\n",
    "- Load domain knowledge and inject it into a system prompt\n",
    "- Build a `QAAgent` async class for policy Q&A\n",
    "- Build a `ClaimsAgent` for multi-turn claims filing\n",
    "- Return **structured JSON** data (not just text)\n",
    "- Route between multiple skills with `MultiSkillAgent`\n",
    "- Test the agent standalone before adding A2A protocol layers\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "**GitHub Models** (default):\n",
    "\n",
    "- GitHub account with a [Personal Access Token](https://github.com/settings/tokens) (no special scopes)\n",
    "- `GITHUB_TOKEN` environment variable set in `.env`\n",
    "\n",
    "**AI Toolkit LocalFoundry** (alternative — no token needed):\n",
    "\n",
    "- VS Code with [AI Toolkit extension](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)\n",
    "- A model loaded and running on port 5272\n",
    "\n",
    "> **GitHub Models docs:** [docs.github.com/en/github-models](https://docs.github.com/en/github-models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981111b",
   "metadata": {},
   "source": [
    "## Agent Architecture Overview\n",
    "\n",
    "Before writing any code, here's what you're building and where it fits in the course.\n",
    "\n",
    "```mermaid\n",
    "graph TB\n",
    "    subgraph Lesson05[\"Lesson 05 — This Notebook\"]\n",
    "        MS[\"MultiSkillAgent\\n(router)\"]\n",
    "        QA[\"QAAgent\\n(policy Q&A)\"]\n",
    "        CA[\"ClaimsAgent\\n(multi-turn filing)\"]\n",
    "        PS[\"PolicySummaryAgent\\n(structured JSON)\"]\n",
    "        MS -->|policy-qa| QA\n",
    "        MS -->|claims-filing| CA\n",
    "        MS -->|policy-summary| PS\n",
    "    end\n",
    "\n",
    "    subgraph Lesson06[\"Lesson 06 — A2A Server\"]\n",
    "        EX[\"InsuranceAgentExecutor\\n(AgentExecutor)\"]\n",
    "        RH[\"DefaultRequestHandler\"]\n",
    "        APP[\"A2AStarletteApplication\\n(port 10001)\"]\n",
    "        EX --> MS\n",
    "        RH --> EX\n",
    "        APP --> RH\n",
    "    end\n",
    "\n",
    "    subgraph Lesson07[\"Lesson 07 — A2A Client\"]\n",
    "        CL[\"A2AClient\"]\n",
    "        CR[\"A2ACardResolver\"]\n",
    "        CR --> APP\n",
    "        CL --> APP\n",
    "    end\n",
    "\n",
    "    style Lesson05 fill:#e8f4f8,stroke:#4a90d9\n",
    "    style Lesson06 fill:#fef9e7,stroke:#f39c12\n",
    "    style Lesson07 fill:#e9f7ef,stroke:#27ae60\n",
    "```\n",
    "\n",
    "The three agent classes (`QAAgent`, `ClaimsAgent`, `PolicySummaryAgent`) are the **business logic**.\n",
    "`MultiSkillAgent` is the router. In Lesson 06, `InsuranceAgentExecutor` wraps the router with\n",
    "the A2A protocol interface, exposing it as a server that Lesson 07's client can discover and call.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa6cb29",
   "metadata": {},
   "source": [
    "## Step 1 — Install Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd6f470c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Dependencies ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# ── Dependencies ──────────────────────────────────────────────────────────────\n",
    "# openai        → OpenAI-compatible SDK (used to call GitHub Models / Phi-4)\n",
    "# python-dotenv → Loads GITHUB_TOKEN from the .env file automatically\n",
    "#\n",
    "# If you have the venv active (a2a-examples kernel selected) these are already\n",
    "# installed. Run this cell anyway to ensure the kernel is up to date.\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "%pip install openai python-dotenv --quiet\n",
    "print(\"Dependencies ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "493e6643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env from: y:\\.sources\\localm-tuts\\a2a\\_examples\\.env\n",
      "GITHUB_TOKEN is set (github_p...)\n",
      "Provider  : github\n",
      "Endpoint  : https://models.inference.ai.azure.com\n",
      "Model     : Phi-4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "# ── Load secrets from .env ─────────────────────────────────────────────────\n",
    "env_path = find_dotenv(raise_error_if_not_found=False)\n",
    "if env_path:\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"Loaded .env from: {env_path}\")\n",
    "else:\n",
    "    print(\"NOTE: .env not found — set GITHUB_TOKEN manually below if needed\")\n",
    "\n",
    "# ── Model provider ────────────────────────────────────────────────────────────\n",
    "# \"github\"       — GitHub Models  (free, needs GITHUB_TOKEN in .env)\n",
    "# \"localfoundry\" — AI Toolkit LocalFoundry  (local, no token needed)\n",
    "PROVIDER = \"github\"  # ← change to \"github\" to use GitHub Models\n",
    "\n",
    "if PROVIDER == \"github\":\n",
    "    token = os.environ.get(\"GITHUB_TOKEN\", \"\")\n",
    "    if token:\n",
    "        print(f\"GITHUB_TOKEN is set ({token[:8]}...)\")\n",
    "    else:\n",
    "        print(\"ERROR: GITHUB_TOKEN is NOT set — cells below will fail until you set it\")\n",
    "    ENDPOINT = \"https://models.inference.ai.azure.com\"\n",
    "    API_KEY = token\n",
    "    MODEL = \"Phi-4\"\n",
    "\n",
    "elif PROVIDER == \"localfoundry\":\n",
    "    ENDPOINT = os.environ.get(\"LOCALFOUNDRY_ENDPOINT\", \"http://localhost:5272/v1/\")\n",
    "    API_KEY = \"unused\"  # LocalFoundry ignores the key\n",
    "    MODEL = os.environ.get(\"LOCALFOUNDRY_MODEL\", \"qwen2.5-0.5b-instruct-generic-gpu:4\")\n",
    "    print(f\"NOTE: AI Toolkit LocalFoundry — ensure a model is running at {ENDPOINT}\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unknown PROVIDER: {PROVIDER!r}\")\n",
    "\n",
    "print(f\"Provider  : {PROVIDER}\")\n",
    "print(f\"Endpoint  : {ENDPOINT}\")\n",
    "print(f\"Model     : {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547e2439",
   "metadata": {},
   "source": [
    "## Step 2 — Configure the Model Client\n",
    "\n",
    "Both **GitHub Models** and **AI Toolkit LocalFoundry** expose an **OpenAI-compatible API**.\n",
    "We use the standard `openai` package — only `base_url` and `api_key` differ between providers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87b9927e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client configured — base_url: https://models.inference.ai.azure.com\n",
      "Model        : Phi-4\n"
     ]
    }
   ],
   "source": [
    "from openai import AsyncOpenAI\n",
    "\n",
    "client = AsyncOpenAI(\n",
    "    base_url=ENDPOINT,\n",
    "    api_key=API_KEY,\n",
    ")\n",
    "\n",
    "print(f\"Client configured — base_url: {client.base_url}\")\n",
    "print(f\"Model        : {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60ee53",
   "metadata": {},
   "source": [
    "## Step 3 — Quick Model Test\n",
    "\n",
    "Before building the agent, verify that the model connection works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37871fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: phi4\n",
      "Answer: 2 + 2 equals 4.\n"
     ]
    }
   ],
   "source": [
    "response = await client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is 2 + 2?\"}],\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "print(f\"Model: {response.model}\")\n",
    "print(f\"Answer: {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db5c170",
   "metadata": {},
   "source": [
    "## Step 4 — Load Domain Knowledge\n",
    "\n",
    "The agent needs a knowledge base to answer domain-specific questions.\n",
    "We load an insurance policy document and inject it into the system prompt.\n",
    "\n",
    "This is **RAG-lite** — simple and effective for bounded domains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb89da60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1763 characters of domain knowledge\n",
      "System prompt: 2024 characters\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a helpful insurance policy assistant.\n",
    "Use the following policy document to answer questions accurately.\n",
    "If the answer is not in the document, say so clearly.\n",
    "Always cite the relevant section when possible.\n",
    "\n",
    "--- POLICY DOCUMENT ---\n",
    "{policy_text}\n",
    "--- END DOCUMENT ---\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_knowledge(path: str) -> str:\n",
    "    \"\"\"Load a knowledge document from disk.\"\"\"\n",
    "    return Path(path).read_text(encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "# Load the insurance policy\n",
    "knowledge = load_knowledge(\"data/insurance_policy.txt\")\n",
    "system_prompt = SYSTEM_PROMPT.format(policy_text=knowledge)\n",
    "\n",
    "print(f\"Loaded {len(knowledge)} characters of domain knowledge\")\n",
    "print(f\"System prompt: {len(system_prompt)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ca9a8",
   "metadata": {},
   "source": [
    "## Step 5 — Build the QAAgent Class\n",
    "\n",
    "The agent encapsulates:\n",
    "\n",
    "- Model client (AsyncOpenAI)\n",
    "- Model name (from `MODEL`)\n",
    "- Domain knowledge (loaded from file)\n",
    "- System prompt (template with injected knowledge)\n",
    "\n",
    "**Key design decisions:**\n",
    "| Decision | Choice | Rationale |\n",
    "|---|---|---|\n",
    "| Async interface | `async def query()` | A2A servers are async — start async from day one |\n",
    "| Class pattern | `QAAgent` class | Clean separation for AgentExecutor wrapping (Lesson 6) |\n",
    "| Low temperature | `0.2` | Factual Q&A needs deterministic responses |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81715056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAAgent class defined.\n"
     ]
    }
   ],
   "source": [
    "class QAAgent:\n",
    "    \"\"\"Question-answering agent backed by the configured model provider.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        knowledge_path: str,\n",
    "        model: str = MODEL,\n",
    "        endpoint: str = ENDPOINT,\n",
    "        api_key: str = API_KEY,\n",
    "        temperature: float = 0.2,\n",
    "    ):\n",
    "        self.client = AsyncOpenAI(\n",
    "            base_url=endpoint,\n",
    "            api_key=api_key,\n",
    "        )\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.knowledge = load_knowledge(knowledge_path)\n",
    "        self.system_prompt = SYSTEM_PROMPT.format(policy_text=self.knowledge)\n",
    "\n",
    "    async def query(self, question: str) -> str:\n",
    "        \"\"\"Send a question to the model and return the answer.\"\"\"\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "            temperature=self.temperature,\n",
    "            max_tokens=2048,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "print(\"QAAgent class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32adbe79",
   "metadata": {},
   "source": [
    "## Step 6 — Test the QA Agent\n",
    "\n",
    "**Always test standalone before wrapping in A2A.** This verifies:\n",
    "\n",
    "- Model connectivity\n",
    "- Knowledge injection\n",
    "- Response quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f7bbc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created with 1763 chars of knowledge\n"
     ]
    }
   ],
   "source": [
    "agent = QAAgent(\"data/insurance_policy.txt\")\n",
    "print(f\"Agent created with {len(agent.knowledge)} chars of knowledge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3225f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is the deductible for the Standard plan?\n",
      "\n",
      "A: The deductible for the Standard plan includes:\n",
      "\n",
      "- Standard Plan Deductible: $500 per incident\n",
      "- Emergency Room Deductible: $250 per visit\n",
      "- Prescription Drug Deductible: $100 per year\n",
      "\n",
      "These details are found under the \"DEDUCTIBLES\" section of the policy document.\n"
     ]
    }
   ],
   "source": [
    "# Test question 1: Specific fact\n",
    "answer = await agent.query(\"What is the deductible for the Standard plan?\")\n",
    "print(\"Q: What is the deductible for the Standard plan?\\n\")\n",
    "print(f\"A: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "796e8623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Are cosmetic procedures covered?\n",
      "\n",
      "A: Cosmetic procedures are generally not covered under the ACME Insurance Standard Policy. The policy document states under the \"EXCLUSIONS\" section:\n",
      "\n",
      "- Cosmetic procedures (unless medically necessary)\n",
      "\n",
      "This means that cosmetic procedures are excluded from coverage unless they are deemed medically necessary. If you believe a procedure is medically necessary, you may need to provide documentation or justification to support your claim.\n"
     ]
    }
   ],
   "source": [
    "# Test question 2: Coverage question\n",
    "answer = await agent.query(\"Are cosmetic procedures covered?\")\n",
    "print(\"Q: Are cosmetic procedures covered?\\n\")\n",
    "print(f\"A: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48ae656c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is the capital of France?\n",
      "\n",
      "A: I'm sorry, but the information about the capital of France is not included in the policy document provided. However, I can tell you that the capital of France is Paris. If you have any questions related to the insurance policy document, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Test question 3: Out-of-scope question (should say \"not in document\")\n",
    "answer = await agent.query(\"What is the capital of France?\")\n",
    "print(\"Q: What is the capital of France?\\n\")\n",
    "print(f\"A: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e691f6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 7 — Build the ClaimsAgent (Multi-Turn)\n",
    "\n",
    "The A2A protocol supports **multi-turn interactions** where an agent can\n",
    "request additional input from the client mid-task (the `input_required` state).\n",
    "\n",
    "The `ClaimsAgent` handles insurance claims filing:\n",
    "\n",
    "1. **Check** if the user provided all required claim fields\n",
    "2. **Ask** for missing fields (→ triggers INPUT_REQUIRED in Lesson 6)\n",
    "3. **Process** the claim when all fields are present\n",
    "4. **Return** structured JSON (claim receipt) — not just text\n",
    "\n",
    "This demonstrates two key A2A concepts:\n",
    "\n",
    "- **Multi-turn conversations** (§3.4 of the A2A spec)\n",
    "- **Structured data exchange** (§6.8 of the A2A spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633f5ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClaimsAgent class defined.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from datetime import datetime, timezone\n",
    "from uuid import uuid4\n",
    "\n",
    "# Required fields for a valid insurance claim\n",
    "REQUIRED_CLAIM_FIELDS = [\"claim_type\", \"date_of_service\", \"amount\", \"description\"]\n",
    "\n",
    "CLAIMS_SYSTEM_PROMPT = \"\"\"\\\n",
    "You are an insurance claims filing assistant. Extract claim data from user messages.\n",
    "\n",
    "Required claim fields:\n",
    "- claim_type: one of \"medical\", \"dental\", \"prescription\", \"emergency\"\n",
    "- date_of_service: date in YYYY-MM-DD format\n",
    "- amount: dollar amount as a string (e.g. \"150.00\")\n",
    "- description: brief description of the service\n",
    "\n",
    "STRICT RULES — you must follow these exactly:\n",
    "- ONLY extract fields that are EXPLICITLY and CLEARLY stated by the user\n",
    "- Do NOT infer, guess, assume, or fabricate any field value\n",
    "- Do NOT add a field unless the user clearly provided that exact value\n",
    "- If a field is absent or ambiguous, omit it from extracted_fields entirely\n",
    "- Do NOT re-extract fields already collected (listed below)\n",
    "\n",
    "Already collected fields (do NOT include these in extracted_fields):\n",
    "{collected}\n",
    "\n",
    "Return ONLY a JSON object with no markdown, no explanation:\n",
    "{{\n",
    "  \"extracted_fields\": {{\"field_name\": \"value\"}}\n",
    "}}\n",
    "\n",
    "If the user provided nothing extractable, return: {{\"extracted_fields\": {{}}}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ClaimsAgent:\n",
    "    \"\"\"Multi-turn claims filing agent.\n",
    "\n",
    "    Maintains state across turns to collect all required claim fields.\n",
    "    Returns structured JSON with extracted fields and missing info.\n",
    "\n",
    "    This pattern supports the A2A INPUT_REQUIRED task state:\n",
    "    - Turn 1: User says \"I need to file a claim for my dental visit\"\n",
    "    - Agent extracts claim_type=dental, asks for date, amount, description\n",
    "    - Turn 2: User provides \"$200 on 2025-01-15 for root canal\"\n",
    "    - Agent extracts all fields, processes the claim\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: str = MODEL,\n",
    "        endpoint: str = ENDPOINT,\n",
    "        api_key: str = API_KEY,\n",
    "    ):\n",
    "        self.client = AsyncOpenAI(base_url=endpoint, api_key=api_key)\n",
    "        self.model = model\n",
    "        # Per-session state: task_id → collected fields\n",
    "        self.sessions: dict[str, dict[str, str]] = {}\n",
    "\n",
    "    async def process(self, user_text: str, session_id: str = \"default\") -> dict:\n",
    "        \"\"\"Process a claims turn. Returns a dict with status and data.\n",
    "\n",
    "        Returns:\n",
    "            {\n",
    "                \"status\": \"input_required\" | \"completed\",\n",
    "                \"missing_fields\": [...],        # if input_required\n",
    "                \"message\": \"...\",               # human-readable\n",
    "                \"claim_receipt\": {...}           # if completed\n",
    "            }\n",
    "        \"\"\"\n",
    "        collected = self.sessions.get(session_id, {})\n",
    "\n",
    "        # Ask LLM to extract only explicitly stated fields from user message\n",
    "        prompt = CLAIMS_SYSTEM_PROMPT.format(\n",
    "            collected=json.dumps(collected) if collected else \"(none yet)\"\n",
    "        )\n",
    "\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": user_text},\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            max_tokens=1024,\n",
    "        )\n",
    "\n",
    "        raw = response.choices[0].message.content\n",
    "\n",
    "        # Parse the JSON from LLM response\n",
    "        try:\n",
    "            # Extract JSON from the response (LLM may wrap in markdown)\n",
    "            json_match = re.search(r\"\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}\", raw, re.DOTALL)\n",
    "            if json_match:\n",
    "                parsed = json.loads(json_match.group())\n",
    "            else:\n",
    "                parsed = json.loads(raw)\n",
    "        except json.JSONDecodeError:\n",
    "            # Fallback: treat as no fields extracted\n",
    "            parsed = {\"extracted_fields\": {}}\n",
    "\n",
    "        # Merge extracted fields into session state\n",
    "        extracted = parsed.get(\"extracted_fields\", {})\n",
    "        collected.update({k: v for k, v in extracted.items() if v})\n",
    "        self.sessions[session_id] = collected\n",
    "\n",
    "        # Determine what's still missing — computed deterministically in Python\n",
    "        missing = [f for f in REQUIRED_CLAIM_FIELDS if f not in collected]\n",
    "\n",
    "        if missing:\n",
    "            return {\n",
    "                \"status\": \"input_required\",\n",
    "                \"collected_fields\": collected,\n",
    "                \"missing_fields\": missing,\n",
    "                \"message\": f\"Please provide: {', '.join(missing)}\",\n",
    "            }\n",
    "        else:\n",
    "            # All fields collected — generate claim receipt\n",
    "            receipt = self._generate_receipt(collected, session_id)\n",
    "            # Clear session\n",
    "            del self.sessions[session_id]\n",
    "            return {\n",
    "                \"status\": \"completed\",\n",
    "                \"claim_receipt\": receipt,\n",
    "                \"message\": f\"Claim {receipt['claim_id']} filed successfully.\",\n",
    "            }\n",
    "\n",
    "    def clear_session(self, session_id: str) -> None:\n",
    "        \"\"\"Remove a claims session (used by cancel).\"\"\"\n",
    "        self.sessions.pop(session_id, None)\n",
    "\n",
    "    def _generate_receipt(self, fields: dict, session_id: str) -> dict:\n",
    "        \"\"\"Generate a structured claim receipt (JSON artifact).\"\"\"\n",
    "        return {\n",
    "            \"claim_id\": f\"CLM-{uuid4().hex[:8].upper()}\",\n",
    "            \"policy_number\": \"ACME-STD-2025-001\",\n",
    "            \"claim_type\": fields.get(\"claim_type\", \"unknown\"),\n",
    "            \"date_of_service\": fields.get(\"date_of_service\", \"unknown\"),\n",
    "            \"amount\": fields.get(\"amount\", \"0.00\"),\n",
    "            \"description\": fields.get(\"description\", \"\"),\n",
    "            \"status\": \"submitted\",\n",
    "            \"filed_at\": datetime.now(timezone.utc).isoformat(),\n",
    "            \"estimated_processing_days\": 30,\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"ClaimsAgent class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb667cf",
   "metadata": {},
   "source": [
    "## Step 8 — Test the ClaimsAgent (Multi-Turn)\n",
    "\n",
    "Simulate a multi-turn conversation:\n",
    "\n",
    "1. User provides partial info → agent asks for more\n",
    "2. User provides remaining info → agent files the claim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7919b1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 1 result:\n",
      "{\n",
      "  \"status\": \"input_required\",\n",
      "  \"collected_fields\": {\n",
      "    \"claim_type\": \"dental\"\n",
      "  },\n",
      "  \"missing_fields\": [\n",
      "    \"date_of_service\",\n",
      "    \"amount\",\n",
      "    \"description\"\n",
      "  ],\n",
      "  \"message\": \"Please provide: date_of_service, amount, description\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "claims_agent = ClaimsAgent()\n",
    "\n",
    "# Turn 1: Partial info\n",
    "result1 = await claims_agent.process(\n",
    "    \"I need to file a dental claim for a root canal\", session_id=\"demo-1\"\n",
    ")\n",
    "print(\"Turn 1 result:\")\n",
    "print(json.dumps(result1, indent=2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a377fe17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 2 result:\n",
      "{\n",
      "  \"status\": \"completed\",\n",
      "  \"claim_receipt\": {\n",
      "    \"claim_id\": \"CLM-1F75BA9A\",\n",
      "    \"policy_number\": \"ACME-STD-2025-001\",\n",
      "    \"claim_type\": \"dental\",\n",
      "    \"date_of_service\": \"2025-01-15\",\n",
      "    \"amount\": \"450.00\",\n",
      "    \"description\": \"root canal procedure\",\n",
      "    \"status\": \"submitted\",\n",
      "    \"filed_at\": \"2026-02-28T21:39:44.748664+00:00\",\n",
      "    \"estimated_processing_days\": 30\n",
      "  },\n",
      "  \"message\": \"Claim CLM-1F75BA9A filed successfully.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Turn 2: Provide the remaining info (date, amount, and description — all at once)\n",
    "result2 = await claims_agent.process(\n",
    "    \"The visit was on 2025-01-15 and it cost $450 for a root canal procedure\",\n",
    "    session_id=\"demo-1\",\n",
    ")\n",
    "print(\"Turn 2 result:\")\n",
    "print(json.dumps(result2, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ed73e1",
   "metadata": {},
   "source": [
    "Notice:\n",
    "\n",
    "- Turn 1 returned `\"status\": \"input_required\"` with a list of `missing_fields`\n",
    "- Turn 2 returned `\"status\": \"completed\"` with a full `claim_receipt` — structured JSON\n",
    "\n",
    "The A2A protocol maps this directly:\n",
    "\n",
    "- `input_required` → `TaskState.input_required` (server pauses, waits for client follow-up)\n",
    "- `completed` → `TaskState.completed` with an `Artifact` containing the receipt JSON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ca02e1",
   "metadata": {},
   "source": [
    "### How Multi-Turn Maps to the A2A Protocol\n",
    "\n",
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant User\n",
    "    participant ClaimsAgent\n",
    "    participant Session as \"sessions dict\\n(in-memory state)\"\n",
    "\n",
    "    User->>ClaimsAgent: \"file a dental claim\"\n",
    "    ClaimsAgent->>Session: get collected = {}\n",
    "    ClaimsAgent-->>User: status=input_required<br/>missing=[date, amount, description]\n",
    "\n",
    "    Note over ClaimsAgent,Session: Session stores claim_type=dental\n",
    "\n",
    "    User->>ClaimsAgent: \"root canal on 2025-01-15 for $450\"\n",
    "    ClaimsAgent->>Session: get collected = {claim_type: dental}\n",
    "    ClaimsAgent->>Session: merge: date=2025-01-15, amount=$450\n",
    "    Note over ClaimsAgent: still missing: description\n",
    "\n",
    "    ClaimsAgent-->>User: status=input_required<br/>missing=[description]\n",
    "\n",
    "    User->>ClaimsAgent: \"root canal procedure\"\n",
    "    ClaimsAgent->>Session: merge: description=root canal procedure\n",
    "    Note over ClaimsAgent: ALL fields present → generate receipt\n",
    "    ClaimsAgent->>Session: del session (cleanup)\n",
    "    ClaimsAgent-->>User: status=completed<br/>claim_receipt={claim_id, ...}\n",
    "```\n",
    "\n",
    "In Lesson 06 these translate directly to A2A protocol events emitted by `InsuranceAgentExecutor`:\n",
    "\n",
    "- `input_required` → `TaskStatusUpdateEvent(state=TaskState.input_required)`\n",
    "- `completed` → `TaskArtifactUpdateEvent(artifact=Artifact(parts=[DataPart(data=receipt)]))`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23daf4a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 9 — Build the PolicySummaryAgent (Structured Data)\n",
    "\n",
    "The A2A protocol supports **structured data parts** (`DataPart`) for machine-readable\n",
    "exchange. This agent returns policy summaries as **JSON artifacts** rather than prose.\n",
    "\n",
    "This demonstrates A2A **Artifact** output (§4.1.7) and **DataPart** (§4.1.6).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3664892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolicySummaryAgent class defined.\n"
     ]
    }
   ],
   "source": [
    "class PolicySummaryAgent:\n",
    "    \"\"\"Returns structured policy summaries as JSON.\n",
    "\n",
    "    Instead of free-text answers, this agent returns machine-readable\n",
    "    data that can be consumed by other agents or UIs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        knowledge_path: str = \"data/insurance_policy.txt\",\n",
    "        model: str = MODEL,\n",
    "        endpoint: str = ENDPOINT,\n",
    "        api_key: str = API_KEY,\n",
    "    ):\n",
    "        self.client = AsyncOpenAI(base_url=endpoint, api_key=api_key)\n",
    "        self.model = model\n",
    "        self.knowledge = load_knowledge(knowledge_path)\n",
    "\n",
    "    async def summarize(self) -> dict:\n",
    "        \"\"\"Generate a structured policy summary.\"\"\"\n",
    "        prompt = f\"\"\"\\\n",
    "Extract the key facts from this insurance policy and return ONLY a JSON object:\n",
    "\n",
    "{self.knowledge}\n",
    "\n",
    "Return this exact JSON structure (fill in values from the document):\n",
    "{{\n",
    "  \"policy_number\": \"...\",\n",
    "  \"plan_name\": \"...\",\n",
    "  \"monthly_premium\": \"...\",\n",
    "  \"annual_premium\": \"...\",\n",
    "  \"deductible\": \"...\",\n",
    "  \"annual_maximum\": \"...\",\n",
    "  \"covered_services\": [\"...\"],\n",
    "  \"exclusions\": [\"...\"]\n",
    "}}\n",
    "\"\"\"\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.0,\n",
    "            max_tokens=2048,\n",
    "        )\n",
    "\n",
    "        raw = response.choices[0].message.content\n",
    "\n",
    "        try:\n",
    "            json_match = re.search(r\"\\{.*\\}\", raw, re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group())\n",
    "            return json.loads(raw)\n",
    "        except json.JSONDecodeError:\n",
    "            return {\"error\": \"Failed to parse structured output\", \"raw\": raw}\n",
    "\n",
    "\n",
    "print(\"PolicySummaryAgent class defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3af9fbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Summary (structured JSON):\n",
      "{\n",
      "  \"policy_number\": \"ACME-STD-2025-001\",\n",
      "  \"plan_name\": \"Standard\",\n",
      "  \"monthly_premium\": \"$150\",\n",
      "  \"annual_premium\": \"$1,800\",\n",
      "  \"deductible\": {\n",
      "    \"standard_plan\": \"$500 per incident\",\n",
      "    \"emergency_room\": \"$250 per visit\",\n",
      "    \"prescription_drug\": \"$100 per year\"\n",
      "  },\n",
      "  \"annual_maximum\": \"$200,000\",\n",
      "  \"covered_services\": [\n",
      "    \"Primary Care Visits: Covered after deductible, 80/20 co-insurance\",\n",
      "    \"Specialist Visits: Covered after deductible, 70/30 co-insurance\",\n",
      "    \"Emergency Room: Covered after ER deductible, 90/10 co-insurance\",\n",
      "    \"Prescription Drugs: Generic: $10 co-pay, Brand Name: $30 co-pay, Specialty: 20% co-insurance after drug deductible\",\n",
      "    \"Preventive Care: Covered at 100%, no deductible\",\n",
      "    \"Mental Health: Covered after deductible, 80/20 co-insurance\",\n",
      "    \"Physical Therapy: Up to 30 visits per year, $25 co-pay per visit\"\n",
      "  ],\n",
      "  \"exclusions\": [\n",
      "    \"Cosmetic procedures (unless medically necessary)\",\n",
      "    \"Experimental treatments not FDA-approved\",\n",
      "    \"Services outside the provider network (except emergencies)\",\n",
      "    \"Pre-existing conditions during the first 90-day waiting period\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test the structured output agent\n",
    "summary_agent = PolicySummaryAgent()\n",
    "summary = await summary_agent.summarize()\n",
    "\n",
    "print(\"Policy Summary (structured JSON):\")\n",
    "print(json.dumps(summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4339c85f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 10 — Multi-Skill Routing\n",
    "\n",
    "Real A2A agents declare **multiple skills** in their Agent Card. The server\n",
    "routes requests to the appropriate skill based on the message content.\n",
    "\n",
    "The `MultiSkillAgent` wraps all three agents and routes based on intent:\n",
    "\n",
    "| Skill            | Agent              | Trigger Pattern                                             |\n",
    "| ---------------- | ------------------ | ----------------------------------------------------------- |\n",
    "| `policy-qa`      | QAAgent            | questions about coverage, deductibles, premiums             |\n",
    "| `claims-filing`  | ClaimsAgent        | \"file a dental claim\", \"submit claim\", \"medical claim\" etc. |\n",
    "| `policy-summary` | PolicySummaryAgent | \"summary\", \"summarize\", \"overview\"                          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d360be76",
   "metadata": {},
   "source": [
    "### Skill Routing Flow\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    Input[\"User message\"] --> Router{\"MultiSkillAgent\\n.detect_skill()\"}\n",
    "\n",
    "    Router -->|regex: 'file.*claim'\\n'dental claim'\\n'submit claim'| Claims[\"ClaimsAgent\\n.process()\"]\n",
    "    Router -->|contains 'summary'\\n'summarize'\\n'overview'| Summary[\"PolicySummaryAgent\\n.summarize()\"]\n",
    "    Router -->|everything else| QA[\"QAAgent\\n.query()\"]\n",
    "\n",
    "    Claims --> CheckComplete{\"All 4 fields\\ncollected?\"}\n",
    "    CheckComplete -->|No| InputRequired[\"status: input_required\\nmissing_fields: [...]\"]\n",
    "    CheckComplete -->|Yes| ClaimReceipt[\"status: completed\\nclaim_receipt: {...}\"]\n",
    "\n",
    "    Summary --> StructuredJSON[\"status: completed\\ndata: {policy JSON}\"]\n",
    "    QA --> TextAnswer[\"status: completed\\nanswer: '...'\"]\n",
    "```\n",
    "\n",
    "**Why skill detection matters for A2A:**\n",
    "The Lesson 06 `InsuranceAgentExecutor` calls `detect_skill()` on every message, then stores the\n",
    "active skill in `self.active_skills[task_id]` so follow-up messages in a multi-turn conversation\n",
    "continue routing to the same skill.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db350aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiSkillAgent class defined.\n"
     ]
    }
   ],
   "source": [
    "class MultiSkillAgent:\n",
    "    \"\"\"Routes requests to the appropriate skill agent.\n",
    "\n",
    "    In Lesson 6, the A2A Agent Card declares these skills, and the\n",
    "    AgentExecutor uses this router to handle incoming messages.\n",
    "    \"\"\"\n",
    "\n",
    "    CLAIM_PATTERN = re.compile(\n",
    "        r\"\\b(file|submit|make|start)\\b.*\\bclaims?\\b\"\n",
    "        r\"|\\bclaims?\\s+(for|about|regarding)\\b\"\n",
    "        r\"|\\b(dental|medical|prescription|emergency)\\s+claims?\\b\",\n",
    "        re.IGNORECASE,\n",
    "    )\n",
    "    SUMMARY_KEYWORDS = [\"summary\", \"summarize\", \"overview\", \"key facts\"]\n",
    "\n",
    "    def __init__(self, knowledge_path: str = \"data/insurance_policy.txt\"):\n",
    "        self.qa_agent = QAAgent(knowledge_path)\n",
    "        self.claims_agent = ClaimsAgent()\n",
    "        self.summary_agent = PolicySummaryAgent(knowledge_path)\n",
    "\n",
    "    def detect_skill(self, user_text: str) -> str:\n",
    "        \"\"\"Detect which skill to route to based on user input.\"\"\"\n",
    "        lower = user_text.lower()\n",
    "        if self.CLAIM_PATTERN.search(lower):\n",
    "            return \"claims-filing\"\n",
    "        if any(kw in lower for kw in self.SUMMARY_KEYWORDS):\n",
    "            return \"policy-summary\"\n",
    "        return \"policy-qa\"\n",
    "\n",
    "    async def handle(\n",
    "        self, user_text: str, skill: str | None = None, session_id: str = \"default\"\n",
    "    ) -> dict:\n",
    "        \"\"\"Handle a request by routing to the correct skill.\n",
    "\n",
    "        Returns:\n",
    "            {\"skill\": str, \"type\": \"text\"|\"structured\"|\"multi_turn\", ...}\n",
    "        \"\"\"\n",
    "        detected_skill = skill or self.detect_skill(user_text)\n",
    "\n",
    "        if detected_skill == \"claims-filing\":\n",
    "            result = await self.claims_agent.process(user_text, session_id)\n",
    "            return {\"skill\": \"claims-filing\", \"type\": \"multi_turn\", **result}\n",
    "\n",
    "        elif detected_skill == \"policy-summary\":\n",
    "            summary = await self.summary_agent.summarize()\n",
    "            return {\n",
    "                \"skill\": \"policy-summary\",\n",
    "                \"type\": \"structured\",\n",
    "                \"status\": \"completed\",\n",
    "                \"data\": summary,\n",
    "            }\n",
    "\n",
    "        else:  # policy-qa\n",
    "            answer = await self.qa_agent.query(user_text)\n",
    "            return {\n",
    "                \"skill\": \"policy-qa\",\n",
    "                \"type\": \"text\",\n",
    "                \"status\": \"completed\",\n",
    "                \"answer\": answer,\n",
    "            }\n",
    "\n",
    "\n",
    "print(\"MultiSkillAgent class defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17451f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  'What is the monthly premium?...' → policy-qa\n",
      "  'I need to file a claim for a dental visit...' → claims-filing\n",
      "  'Give me a summary of my policy...' → policy-summary\n"
     ]
    }
   ],
   "source": [
    "multi = MultiSkillAgent()\n",
    "\n",
    "# Test skill routing\n",
    "tests = [\n",
    "    \"What is the monthly premium?\",  # → policy-qa\n",
    "    \"I need to file a claim for a dental visit\",  # → claims-filing\n",
    "    \"Give me a summary of my policy\",  # → policy-summary\n",
    "]\n",
    "\n",
    "for text in tests:\n",
    "    skill = multi.detect_skill(text)\n",
    "    print(f\"  '{text[:50]}...' → {skill}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c225286a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skill: policy-qa | Type: text\n",
      "Answer: The policy outlines several deductibles:\n",
      "\n",
      "1. **Standard Plan Deductible**: $500 per incident.\n",
      "2. **E...\n",
      "\n",
      "Skill: claims-filing | Type: multi_turn | Status: completed\n",
      "Claim Receipt: {\n",
      "  \"claim_id\": \"CLM-41BD63ED\",\n",
      "  \"policy_number\": \"ACME-STD-2025-001\",\n",
      "  \"claim_type\": \"dental\",\n",
      "  \"date_of_service\": \"2025-02-01\",\n",
      "  \"amount\": \"300\",\n",
      "  \"description\": \"a crown\",\n",
      "  \"status\": \"submitted\",\n",
      "  \"filed_at\": \"2026-02-28T21:40:40.623841+00:00\",\n",
      "  \"estimated_processing_days\": 30\n",
      "}\n",
      "\n",
      "Skill: policy-summary | Type: structured\n",
      "Data: {\n",
      "  \"policy_number\": \"ACME-STD-2025-001\",\n",
      "  \"plan_name\": \"Standard\",\n",
      "  \"monthly_premium\": \"$150\",\n",
      "  \"annual_premium\": \"$1,800\",\n",
      "  \"deductible\": {\n",
      "    \"standard_plan\": \"$500 per incident\",\n",
      "    \"emergen...\n"
     ]
    }
   ],
   "source": [
    "# Exercise all three skills\n",
    "\n",
    "# 1. Policy Q&A\n",
    "r1 = await multi.handle(\"What is the deductible?\")\n",
    "print(f\"Skill: {r1['skill']} | Type: {r1['type']}\")\n",
    "print(f\"Answer: {r1['answer'][:100]}...\")\n",
    "print()\n",
    "\n",
    "# 2. Claims Filing — multi-turn\n",
    "r2 = await multi.handle(\n",
    "    \"I need to file a claim for dental work on 2025-02-01 — $300 for a crown\",\n",
    "    session_id=\"test-claim\",\n",
    ")\n",
    "print(f\"Skill: {r2['skill']} | Type: {r2['type']} | Status: {r2['status']}\")\n",
    "if r2[\"status\"] == \"completed\":\n",
    "    print(f\"Claim Receipt: {json.dumps(r2['claim_receipt'], indent=2)}\")\n",
    "else:\n",
    "    print(f\"Missing: {r2['missing_fields']}\")\n",
    "print()\n",
    "\n",
    "# 3. Policy Summary — structured data\n",
    "r3 = await multi.handle(\"Give me a policy summary\")\n",
    "print(f\"Skill: {r3['skill']} | Type: {r3['type']}\")\n",
    "print(f\"Data: {json.dumps(r3['data'], indent=2)[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd06257d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 11 — Experiment\n",
    "\n",
    "Try these variations:\n",
    "\n",
    "- Change the `temperature` (0.0 for max determinism, 0.8 for more creativity)\n",
    "- Try a multi-turn claims conversation with partial info each turn\n",
    "- Ask the summary agent and compare with the Q&A agent\n",
    "- Modify `CLAIM_PATTERN` regex to test skill routing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d90a012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skill: policy-qa\n",
      "Result: {\n",
      "  \"skill\": \"policy-qa\",\n",
      "  \"type\": \"text\",\n",
      "  \"status\": \"completed\",\n",
      "  \"answer\": \"The monthly premium for the Standard Plan is $150. This information is found in the \\\"COVERAGE SUMMARY\\\" section of the policy document.\"\n",
      "}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Try your own question!\n",
    "your_question = \"How much is the monthly premium?\"\n",
    "\n",
    "result = await multi.handle(your_question)\n",
    "print(f\"Skill: {result['skill']}\")\n",
    "print(f\"Result: {json.dumps(result, indent=2, default=str)[:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06285b5a",
   "metadata": {},
   "source": [
    "## A2A Protocol Coverage — What This Agent Enables\n",
    "\n",
    "| A2A Feature              | Agent Capability          | Lesson 6 Maps To           |\n",
    "| ------------------------ | ------------------------- | -------------------------- |\n",
    "| Multi-Turn (§3.4)        | ClaimsAgent sessions      | `TaskState.input_required` |\n",
    "| Artifacts (§4.1.7)       | Structured claim receipts | `TaskArtifactUpdateEvent`  |\n",
    "| DataPart (§4.1.6)        | JSON policy summaries     | `DataPart` in artifacts    |\n",
    "| Multiple Skills (§4.4.5) | 3-skill router            | Agent Card `skills[]`      |\n",
    "| Task Lifecycle (§4.1.3)  | Status tracking           | `working` → `completed`    |\n",
    "| Text Parts (§4.1.6)      | Q&A answers               | `TextPart` in messages     |\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "This multi-skill agent is the **foundation** for the A2A server.\n",
    "\n",
    "- **Lesson 6** → Wrap with AgentExecutor + Rich Agent Card (3 skills, streaming, artifacts)\n",
    "- **Lesson 7** → Client exercises all capabilities: multi-turn, artifacts, task management\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "A2A Examples (Python 3.11)",
   "language": "python",
   "name": "a2a-examples"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
