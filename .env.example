# Copy this file to .env and fill in your values.
# The real .env is git-ignored — never commit secrets.

# ── GitHub Models ──────────────────────────────────────────────
# Personal Access Token from https://github.com/settings/tokens
# No special scopes required. Free tier — no billing.
# Docs: https://docs.github.com/en/github-models
GITHUB_TOKEN=ghp_your_github_personal_access_token_here

# ── AI Toolkit LocalFoundry ───────────────────────────────────
# VS Code AI Toolkit → Models → Load a model → Run
# The extension hosts an OpenAI-compatible server on localhost.
# Override the defaults below if you changed the port or model.
# LOCALFOUNDRY_ENDPOINT=http://localhost:5272/v1/
# LOCALFOUNDRY_MODEL=qwen2.5-0.5b-instruct-generic-gpu:4

# ── Future providers (uncomment when needed) ──────────────────
# Azure AI Foundry (Kimi-K2, Kimi-K2-Thinking) — Lessons 08+
# AZURE_AI_FOUNDRY_URL=https://your-endpoint.inference.ai.azure.com
# AZURE_AI_FOUNDRY_KEY=your_foundry_key_here
